---
title: "Multivariate Analysis and Metabolite ID-ing"
author: "Torben Kimhofer"
date: "`r Sys.Date()`"
output: 
  BiocStyle::html_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Multivariate Analysis and Metabolite ID-ing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = requireNamespace("nmrData", quietly = TRUE)
)

has_data <- requireNamespace("nmrData", quietly = TRUE)
```

```{r no-data-msg, echo = FALSE, results = "asis"}
if (!has_data) {
  cat("## Tutorial Unavailable\n\nThis vignette requires the external package **nmrData** and access to large raw NMR datasets, which are not shipped with this package due to their size.\n\nTo run the full tutorial locally, please install `nmrData` from GitHub:\n\n```r\nremotes::install_github(\"tkimhofer/nmrData\")\n```\n")
}
```


This tutorial illustrates a multivariate statistical analysis workflow for NMR-based metabolic profilig using the *metabom8* R package.

```{r load-pack, fig.show='hold', message=FALSE, warning=FALSE}
# load packages
if (!requireNamespace("nmrData", quietly = TRUE)) {
  remotes::install_github("tkimhofer/nmrData")
}
library(metabom8)
library(nmrdata)
```


# Data

Proton (^1^H) NMR data are available in the *nmrData* package (www.github.com/tkimhofer) and constitute standard 1D experiments acquired from murine urine samples. Samples were collected longitudinally with a single collection point before and multiple collection points after bariatric surgery was performed. Data acquisition was performed on a 600 MHz Bruker Avance III spectrometer, equipped with a 5 mm triple resonance (TXI) probe operating at 300 K. Further information on study design, experimental setup and data collection can be found in Jia Li *et al.*^[Li, Jia V., *et al.* (2011) Metabolic surgery profoundly influences gut microbial-host metabolic cross-talk. *Gut* 60.9, 1214-1223.]

```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# For reproducibility
set.seed(153)
```


## Prerequisites
Data have been preprocessed as illustrated in Tutorial I. In short, spectral regions that bear no quantitative or biological information were excised, baseline correction was performed, and spectra were then normalised using probabilistic quotient normalisation (PQN).

Let's get started with the analysis:

## Import
Pre-processed data are imported with the `data()` command. The data are saved as a list, and the first task is to assign each list element to a variable.
```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# Load data
data(bariatric)

# Declare variables
Xn<-bariatric$X.pqn # PQN-normalised NMR data matrix
dim(Xn)

ppm<-bariatric$ppm     # chemical shift vector in ppm
length(ppm)

meta<-bariatric$meta   # spectrometer metadata
dim(meta)

an<-bariatric$an       # sample annotation
dim(an)

# list all environment varaibales
ls()
```

The following variables should be in the R workspace after executing the code snippet above:

* *Xn* - preprocessed NMR data matrix where rows represent spectra and columns represent ppm variables
* *ppm*   - chemical shift vector in part per million (ppm), it's length equals to the number of columns of Xn *length(ppm)==ncol(Xn)*
* *an*    - sample annotation data frame containing information about each sample (e.g. group membership, confounder variables)
* *meta*  - spectrometer metadata, e.g., probe temperature at acquisition (not essential for this tutorial)


## Visual inspection
Let's start with a visual inspection of the preprocessed NMR spectra using **matspec()**:
```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# Visualise the first ten spectra
matspec(Xn[1:10,], ppm, shift = c(0,10), interactive=FALSE)
```

The pre-processed spectra range from 0.5 to 9.5 ppm, the water signal has been removed and the baseline is fairly flat. 

# Unsupervised Analysis
PCA offers an initial unsupervised view of major variation in the dataset, before moving to supervised approaches that directly incorporate the response variable.

## PCA
In the first analysis step, data are interrogated using Principal Component Analysis (PCA). PCA is a compression technique that represents high‑dimensional spectroscopic data (here, >56,300 spectral variables) with only a few latent (unobserved) components. Each principal component (PC) is a weighted linear combination of the original variables. The weights (PCA loadings) are chosen to preserve systematic variation across samples. Collinear variables—e.g., metabolites that share structural or biological relationships—tend to have similar PC loadings, and different PCs capture different variation trends.

Typically, PCA provides a good overview of variable patterns by inspecting the first few components.

In `metabom8`, a PCA can be calculated with **pca()**. Key input arguments are the preprocessed NMR matrix (*X=Xn*), the max. number of principal components (*pc=2*), and centering/scaling parameters. Here, the data will be mean centered (*center=TRUE*) and unit variance scaled (*scale="UV"*).

```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# Perform PCA
pca_model=pca(X=Xn, pc=2, scale='UV', center=TRUE)
```

The object *pca.model* contains different slots describing the PCA model - including the scores (*t*) and model loadings (*p*) for each PC.

### Scores Plot
PCA scores can be visualised with **plotscores()** and loadings with **plotload()**. Input include the PCA model (*obj=pca_model*), , the axes to plot (*pc=c(1,2)*), and a list that specifies aesthetics such as point colour (*an=list([variable])*).

In this example, point colour indicates the treatment (e.g., surgical procedure): none (Pre‑op), Roux‑en‑Y gastric bypass (RYGB, a type of bariatric surgery), or sham surgery. The latter is a control group, included to account for incidental effects induced by the surgical procedure (anesthesia, incision, etc.).

```{r, fig.show='hold', fig.width = 6, fig.height = 5, message=FALSE, warning=FALSE}
# Plot PCA results: scores of the first two components
plotscores(obj=pca_model, pc=c(1,2), an=list(Surgery=an$Class), title='PCA - Scores plot')
```

The scatter plot shows PCA scores of the first two PCs.Each point represents an NMR spectrum (a row of $Xn$). The percentages on the axes indicate the proportion of total variation explained by each PC ($R^2$). The dotted ellipse is Hotelling’s $T^2$, a multivariate analogue of a confidence interval used to flag potential outliers.

Additional graphics parameters are passed to **plotscores()** function. For example, point shape and text labels can be supplied as the second and third elements of $an$, respectively.:

```{r, fig.show='hold', fig.width = 6, fig.height = 5, message=FALSE, warning=FALSE}
# define scores that should be labelled
idx<-which(scores(pca_model)[,2]>20 & an$Class=='RYGB') # PC 2 scores above 20 and in group RYGB

# construct label vector with mouse IDs
outliers<-rep('', nrow(an))
outliers[idx]<-an$ID[idx]

# Plot PCA scores, colour according to class, point shape according to time of sample collection and label outliers
plotscores(obj=pca_model, pc=c(1,2), an=list(
  Class=an$Class,         # point colour
  Timepoint=an$Timepoint, # point shape
  ID=outliers),           # point label
  title='PCA - Scores plot')
```

### Loadings Plot

In NMR-based metabonomics, PCA loadings are typically visualised as line plots resembling conventional NMR spectra. In metabom8, this is done by the **plotload()** function. It's primary inputs are the PCA model object (*mod=pca_model*) and the number of the principal component to display (eg., *pc=1*). In the example below, loadings for the first and second principal components are plotted individually. The final plot focuses on the aromatic chemical shift region (6–9 ppm).

```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# Plot PCA loadings
plotload(mod=pca_model, pc=1) # 1st principal component 
plotload(mod=pca_model, pc=2) # 2ndt principal component 
plotload(mod=pca_model, pc=2, shift=c(6,9))  # 2nd principal component chemical shift region 6-9 ppm
```

In the loadings plot:
- The x-axis represents the chemical shift of each variable, similar to an NMR spectrum.
- The y-axis reflects the covariance between PCA scores and the original spectral variables—indicating both the direction and magnitude of each variable's contribution to the component.
- The colour gradient encodes the normalised intensity of each loading value, ranging from 0 to 1.

PCA scores and loadings plots are inherently linked: peaks highlighted in warm colours (e.g., red) correspond to variables that are most influential in distinguishing samples with positive (or negative) scores. The direction (up or down) indicates the sign of the association.

#  Supervised Analysis
A clustering trend by surgery type is visible in the PCA scores plot. However, PCA is an unsupervised technique: it does not explicitly model group differences (e.g., sham vs RYGB surgery) or trends related to a continuous outcome variable (e.g., recovery time).
In human NMR urine spectra, PCA often highlights variation from environmental factors (e.g., diet, medication). In contrast, the murine samples in this study were acquired under tightly controlled conditions (e.g., defined diet and light/dark cycles), thereby reducing unrelated variability and allowing treatment effects to emerge more clearly—even in the first two components.

To explicitly model treatment effects, we use a supervised approach: Orthogonal Projections to Latent Structures, or **Orthogonal Partial Least Squares (O-PLS)**.^[Trygg, J., *et al.* (2002). Orthogonal projections to latent structures (O-PLS). *Journal of Chemometrics*, 16.3, 119-28.]


## O-PLS
O-PLS extends PCA by associating the NMR data matrix (X) with an external outcome variable (Y), such as treatment group. It decomposes systematic variation into Y-predictive and Y-orthogonal components. The predictive component captures variation directly associated with the outcome, while the orthogonal components model structured variation that is independent of Y—often technical or biological noise (e.g., batch effects).

Only the predictive component is used for interpretation with respect to the study outcome. 


### Model overfitting and underfitting
In O‑PLS, the orthogonal components capture structured variation in X that is unrelated to Y (e.g., batch effects, dilution, baseline drift). Choosing too few orthogonal components leaves residual, Y‑orthogonal structure in the predictive space (underfitting), while choosing too many starts to model noise and can destabilize the Y‑predictive relationship (overfitting). The goal is a parsimonious model that removes enough Y‑orthogonal structure to clarify the predictive component without eroding generalizability. Practical selection is based on resampling criteria (e.g., cross‑validated Q²/AUROC), permutation tests, and diagnostics such as DModX and residual inspection.

### $Q^2$ and $AUROC_{CV}$
Cross‑validation is used to determine the optimal number of orthogonal components in O‑PLS. The data are repeatedly split into a training set (to fit the model) and a validation set (to assess prediction).
- Regression (continuous Y): Predictive accuracy is summarized by $Q^2$ (e.g., $1 − PRESS/TSS$), which ranges up to 1 for perfect prediction and can be zero or negative when prediction is poor. Higher Q² indicates better generalization.
- Classification (categorical Y): Performance is assessed by the cross‑validated area under the receiver operating characteristic curve ($AUROC_{CV}$), which is 1 for perfect prediction, ~0.5 for chance‑level, and approaches 0 for systematically inverted predictions.
In metabom8, the number of components is selected automatically using cross‑validated $Q^2$ (regression) or $AUROC_{CV}$ (classification), stopping when additional orthogonal components no longer improve the chosen metric.

### Cross-validation (CV) methods
`metabom8` implements both k-fold cross-validation and Monte Carlo cross-validation (MCCV) to assess model generalisability and guide component selection.

- **K-fold CV**: The dataset is randomly partitioned into k approximately equal-sized subsets (folds). In each round, one fold is held out as the test set, and the model is trained on the remaining k – 1 folds. This is repeated k times so that each subset serves once as the test set. The average performance across folds is used to evaluate predictive power. This approach is straightforward and efficient for moderately sized datasets.

- **Monte Carlo CV (MCCV)**: Also known as repeated random subsampling CV, this approach involves repeatedly (e.g., 50–200 times) splitting the data into a training set and test set at random. A fixed proportion of the data (e.g., 2/3) is used for training, and the remaining 1/3 for testing in each iteration. Since samples are randomly reassigned in each repetition, MCCV provides a more robust estimate of model stability and variance, particularly useful for smaller datasets.

**Parameters:**

- For k-fold, the parameter k defines the number of folds.
- For MCCV, two parameters are relevant:
  - k: Number of resampling repetitions (e.g., 100)
  - ratio: Proportion of the dataset used for training in each round (e.g., 2/3)

MCCV allows for greater randomness and variance estimation across splits, especially when the total sample size is small and strict partitioning into folds would leave very few samples in each test set.

### O-PLS model training and statistical validation
An O-PLS model is calculated with the function **olps()**. The minimum input arguments are the NMR data matrix (*X=Xn*) and the outcome variable(s) of interest (*Y=[outcome variable]*), such as surgical procedure. Additional arguments are available—e.g., statistical validation settings—but these are not discussed here. Further details can be found in the function help: *?opls*.

```{r, fig.show='hold', fig.width = 7.2, fig.height = 4, message=FALSE, warning=FALSE}
# Exclude pre-op group
idx=an$Class!='Pre-op'
X=Xn[idx,]
Y=an$Class[idx]

# Train O-PLS model
opls.model=opls(X,Y)
```
The model summary plot shows the O-PLS parameters, with each bar set corresponding to a model configuration (number of predictive + orthogonal components). The selected model includes one predictive and one orthogonal component (denoted 1+1). For comparison, a more complex model (1+2) is also shown as a semi-transparent bar group, which helps evaluate the automatic component selection process.

You can also return the model summary as a table:
```{r, echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
summary(opls.model)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(summary(opls.model))
```

- $R2X$  indicates the proportion of variation explained in the predictor matrix X.
- $R2Y$ represents the variation explained in the outcome variable Y.

Both values range from 0 to 1, where values closer to 1 imply stronger model fit.
## OPLS Model Interpreation
### Distance to the Model in *X* Space 
DModX is a diagnostic tool used to identify model outliers based on their distance to the O-PLS model in X space. In this context, X refers to the NMR data matrix. You can compute DModX using  **dmodx()** function:
```{r, fig.show='hold', fig.width = 6, fig.height = 5, message=FALSE, warning=FALSE}
distX=dmodx(mod =opls.model, plot=TRUE)
```
In the plot, each point corresponds to a sample, and the dotted line represents the 95% confidence limit. Samples above this threshold are considered moderate outliers. If a trend or structure is observed among the outliers, further investigation is warranted. The variable *distX* is a data frame of DModX values that can be used for additional inspection.

### Visualisation of O-PLS Scores and Loadings
O-PLS results are typically visualised using scores plots, where the x-axis shows the predictive component and the y-axis shows one orthogonal component. Use **plotscores()** to create this plot (refer to the PCA section for input structure). One additional argument is *cv.scores*, which determines whether cross-validated (CV) scores are shown. These CV scores are estimated during internal validation and are more robust than standard scores.

```{r, fig.show='hold', fig.width = 6, fig.height = 5, message=FALSE, warning=FALSE}
# Plot OPLS scores
plotscores(obj=opls.model, an=list(
  Surgery=an$Class[idx],          # colouring according to surgery type
  Timepoint=an$Timepoint[idx]),   # linetype according to timepoint
  title='OPLS - Scores plot',     # plot title
  cv.scores = TRUE)                  # visualise cross-validated scores
```

The resulting plot shows clear separation between the surgery groups, with discriminative power concentrated along the x-axis—typical for O-PLS compared to PLS.

The y-axis (orthogonal component) is mathematically unrelated to the outcome Y. Still, it can sometimes capture technical or systematic effects. In this case, it appears related to spectral normalisation, part of the data preprocessing pipeline (not shown here).

### Loadings Plot and Spetral Overlay

To visualise variable contributions to the predictive component, use plotload():

```{r, fig.show='hold', fig.width = 6, fig.height = 5, message=FALSE, warning=FALSE}
plotload(opls.model, title = 'OPLS-DA Loadings', shift = c(0.5, 9.5))
```

You can also specify *type = "backscaled"* to visualise back-scaled loadings, which help interpret contributions in the original spectral units. For more details on back-scaling or covariance-based loadings, refer to *?plotload* or Cloarec et al.^[Cloared, O., *et al.* (2005). Evaluation of the Orthogonal Projection on Latent Structure Model Limitations Caused by Chemical Shift Variability and Improved Visualization of Biomarker Changes in 1H NMR Spectroscopic Metabonomic Studies. *Analytical Chemistry*. 77.2, 517-26.]

The O-PLS loadings plot highlights spectral regions that differ systematically between the RYGB and Sham control groups. It is often useful to examine these regions in more detail, comparing the loadings to the actual NMR spectra. This can be done with specload(), which overlays model loadings with group-averaged spectra.

From the plot above, the region between 7.45 and 7.5 ppm shows high importance. Let’s zoom into this:

```{r, fig.show='hold', fig.width = 7.2, fig.height = 5, message=FALSE, warning=FALSE}
specload(mod=opls.model, shift=c(7.3,7.45), an=list(
  facet=an$Class[idx]), 
  type='backscaled', 
  alp = 0.5, 
  title = 'Overlayed Spectra with Backscaled Loadings')
```

The gradient-filled line at the top shows the back-scaled loadings. Below that, overlaid NMR spectra are shown, colour-coded by group. Two multiplets at ~7.365 and ~7.425 ppm are clearly more intense in the RYGB group, indicating these features contribute to class separation.


# Metabolite Indentifiation
The following section outlines a standard pipeline for identifying metabolites that exhibit high variable importance in the OPLS-DA model.

## Statistical Total Correlation Spectrsocopy (STOCSY)
A single metabolite often gives rise to multiple resonances in the NMR spectrum due to its chemical structure. Therefore, identifying structurally related signals using correlation analysis is a common strategy. In metabolomics, this is known as Statistical Total Correlation Spectroscopy (STOCSY).

```{r, fig.show='hold', fig.width = 7.2, fig.height = 5, message=FALSE, warning=FALSE}
# define driver peak (the ppm variable where all other spectral variables will be correlated to)
driver1<-7.834
# perform stocsy
stocsy_model<-stocsy(Xn, ppm, driver1) 
# zoom-in different plot regions
plotStocsy(stocsy_model, shift=c(7,8))
plotStocsy(stocsy_model, shift=c(3.9, 4))


# observed signals:
# multiplet @ 7.56
# multiplet @ 7.65
# doublet @ 7.84
# doublet @ 3.97 ppm
```

These identified peak patterns can be used to query spectroscopic reference databases. One of the most widely used databases for metabolic profiling is the *Human Metabolome Database (HMDB)**. 

To proceed: 
1. Visit www.hmdb.ca
2. Use the NMR search utility 
3. Enter the observed chemical shifts (with a tolerance of 0.01 ppm) to search for potential compound matches

This database-driven approach helps generate putative metabolite identifications. However, it is typically only the first step. Confirmatory analyses using 2D NMR experiments or spiking with known standards are often required to fully characterise unknown compounds. 


# Summary
This vignette demonstrated multivariate statistical analysis of NMR-based metabolic phenotyping data using PCA and O-PLS-DA via the *metabom8* package. After establishing a statistically validated O-PLS model, variables of interest were extracted and interpreted through visualisation tools.

Finally, STOCSY was applied to identify structural correlations among NMR peaks. These correlations, together with the supervised model loadings, enabled the formulation of putative metabolite identities by querying reference databases such as HMDB.

This workflow illustrates how chemometric techniques and visualisation tools can be combined to guide and support metabolite identification in complex biological datasets.


## Session Info

```{r session-info, echo=FALSE}
sessionInfo()


